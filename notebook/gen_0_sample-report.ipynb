{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Purpose\n",
    "This notebook will allow for the creation of sample documents that can then be used in the other notebooks. The purpose here is to experiment with using GenAI to also create sample data for demonstrations.\n",
    "\n",
    "## Setup\n",
    "The functions defined below will use Chat Completions to create a series of status reports about a software project based on the initial prompt. A loop will keep adding the previous report to ensure consistency. The reports are then written to the local file system as both the original Markdown and also PDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!pip install pypdf reportlab markdown python-dotenv openai --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensure imports are present and correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI\n",
    "import os\n",
    "from pypdf import PdfWriter\n",
    "from reportlab.lib.pagesizes import letter\n",
    "from reportlab.pdfgen import canvas\n",
    "from reportlab.lib.styles import getSampleStyleSheet\n",
    "from reportlab.platypus import SimpleDocTemplate, Paragraph\n",
    "import markdown\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "This notebook leverages .env files and uses relative pathing to select the correct one. It is intended that the .env file exist in the same level of the folder structure as the notebook itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables from .env file\n",
    "load_dotenv(dotenv_path=\".env\")\n",
    "\n",
    "# Function to generate a prompt and get a response from Azure OpenAI\n",
    "def generate_prompt(prompt):\n",
    "    client = AzureOpenAI(\n",
    "        azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "        api_key=os.getenv(\"AZURE_OPENAI_KEY\"),\n",
    "        api_version=\"2024-02-01\"\n",
    "    )\n",
    "    \n",
    "    conversation=[\n",
    "            {\"role\": \"system\", \"content\": \n",
    "             \"\"\"You are a helpful assistant. You will help create synthetic data. \n",
    "             The data you will create are status reports for a project to improve efficiency in a company call center. The software development project is looking to add AI capabilities to an existing applications. The\n",
    "             team doing the work are experienced developers but new to generative AI solutions. To compensate a team of data scientists and data engineers have been integrated\n",
    "             into the larger team. The goal of the project is reduce time to resolution for a support case thus increasing customer satisfaction and improving the work life of the call center agents. The project is in its final weeks and \n",
    "             numerous issues have been identified. **BE CREATIVE WITH THE ISSUES YOU CREATE**. The project is in a critical phase and leadership wants daily updates. The status report will include the following sections: 1. Project Overview, 2. Current Status, 3. Issues and Risks, 4. Next Steps. IMPORTANT: The response should be in Markdown format and contain nothing more than what the report specifies.\"\"\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}]\n",
    "\n",
    "    combined_report = \"\"\n",
    "    for i in range(4):\n",
    "        response = client.chat.completions.create(\n",
    "            model=os.getenv(\"AZURE_OPENAI_MODEL\"),\n",
    "            messages=conversation\n",
    "        )\n",
    "\n",
    "        write_to_markdown(response.choices[0].message.content, f\"call-center-status{i}.md\")\n",
    "        combined_report += response.choices[0].message.content\n",
    "        write_to_pdf(response.choices[0].message.content, f\"call-center-status-report{i}.pdf\")\n",
    "\n",
    "        conversation.append({\"role\": \"assistant\", \"content\": response.choices[0].message.content})\n",
    "        conversation.append({\"role\": \"user\", \"content\": \"Based on the previous report, create a new report with the same sections but different content that reflects the current status of the project.\"})\n",
    "\n",
    "    # Write the final report to a PDF file\n",
    "    write_to_pdf(combined_report, \"call-center-status-report.pdf\")\n",
    "\n",
    "# Function to write the output to a PDF file\n",
    "def write_to_pdf(text, filename):\n",
    "    # Convert markdown to HTML\n",
    "    html_text = markdown.markdown(text)\n",
    "    \n",
    "    # Create a PDF document\n",
    "    pdf = SimpleDocTemplate(os.path.join('..', 'examples', filename), pagesize=letter)\n",
    "    styles = getSampleStyleSheet()\n",
    "    story = [Paragraph(text, styles[\"Normal\"])]\n",
    "    \n",
    "    # Build the PDF\n",
    "    pdf.build(story)\n",
    "\n",
    "# Function to write the output to a Markdown file\n",
    "def write_to_markdown(text, filename):\n",
    "    with open(os.path.join('..', 'examples', filename), 'w') as f:\n",
    "        f.write(markdown.markdown(text))\n",
    "\n",
    "\n",
    "# Main function to run the script\n",
    "if __name__ == \"__main__\":\n",
    "    prompt = \"Create a status report for a software development project. Assume the project is in a critical phase and leadership wants daily updates. The current status reflects ongoing challenges with defect burndown and challenges with the new feature.\"\n",
    "    generate_prompt(prompt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
