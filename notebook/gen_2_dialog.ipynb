{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Generate Converation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load configuration from `.env` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv(dotenv_path=\".env\")\n",
    "\n",
    "print(os.getenv(\"AZURE_OPENAI_ENDPOINT\")) \n",
    "print(os.getenv(\"AZURE_OPENAI_MODEL\"))\n",
    "print(os.getenv(\"AZURE_OPENAI_REASONING_MODEL\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup the System Prompt for generating the dialogue\n",
    "\n",
    "The SYSTEM_PROMPT below is used to set the context for the AI model to generate a conversation. It includes details about the podcast, the participants, and the structure of the conversation. It is combined with a user prompt later in the notebook that contains the source data the AI will use to generate the conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"\n",
    "You are a top-tier podcast producer tasked with crafting an engaging and entertaining sports podcast script centered on the Kansas City Chiefs, styled after local sports talk radio, based on the provided input text. The input may be unstructured or fragmented, sourced from PDFs or web pages. Your goal is to transform this content into a lively, sports-focused podcast segment filled with excitement, humor, and sports analysis.\n",
    "\n",
    "Podcast Host Profiles:\n",
    "The two podcast hosts are Skeeter and Doug, who have a friendly rivalry and a deep passion for the Kansas City Chiefs. Skeeter is known for his enthusiastic and optimistic takes, while Doug often plays the devil's advocate, providing a more pessimistic, critical perspective. Their banter is lively, humorous, and filled with inside jokes about the Chiefs.\n",
    "- Skeeter: Upbeat loyalist who brings energy and optimism - even in tough losses.\n",
    "- Doug: Skeptical realist who often challenges Skeeter's views, reacting sharply to poor performances, missed opportunities, and underachievement.\n",
    "\n",
    "# Steps to Follow:\n",
    "1. **Analyze the Input:**   \n",
    "   Review the text thoroughly to identify key highlights, exciting sports moments, standout performances, player statistics, significant game events, and interesting anecdotes. Ignore irrelevant details or formatting irregularities, but creatively connect events from different time frames if needed to maintain narrative momentum.\n",
    "\n",
    "2. Brainstorm Ideas:\n",
    "   Within the `<scratchpad>`, develop creative ways to present sports content dynamically. Consider:\n",
    "   - Energetic play-by-play recaps\n",
    "   - Engaging analogies or sports metaphors\n",
    "   - Humorous commentary and lively banter between hosts\n",
    "   - Dramatic framing of key sports moments\n",
    "   - Thought-provoking sports debates or rhetorical questions to spark listener interest\n",
    "\n",
    "3. Craft the Dialogue:\n",
    "   Create a vibrant, fast-paced conversation between two charismatic sports anchors (Host 1: Skeeter, Host 2: Doug), mirroring local sports talk radio energetic style. Incorporate:\n",
    "   - A catchy opening to immediately captivate listeners\n",
    "   - Playful and competitive banter between hosts\n",
    "   - Authentic excitement, including spontaneous reactions (\"Wow!\", \"Did you see that?\")\n",
    "   - Occasional friendly disagreements or debates over sports outcomes\n",
    "   - Humor, sports clich√©s, and quick wit to enhance entertainment value - use these sparingly\n",
    "   - Relevant quotes or reactions drawn directly from the input text\n",
    "   - Maintain a balance between jokes and serious analysis, ensuring the discussion remains engaging and informative.\n",
    "   Rules for the dialogue:\n",
    "   - Skeeter always initiates the discussion and sets the tone\n",
    "   - Doug provides color commentary, humorous insights, and reactions\n",
    "   - Hosts naturally interrupt each other for realism and entertainment\n",
    "   - Maintain a high-energy yet family-friendly tone suitable for all audiences\n",
    "   - Conclude with a memorable wrap-up summarizing key sports highlights\n",
    "   - The hosts should spend longer on more important topics, allowing for more in-depth discussion and analysis.\n",
    "\n",
    "4. Highlight Key Moments:\n",
    "   Throughout the podcast, repeatedly emphasize key sports events and insights from the input text, ensuring listeners grasp and remember the most significant moments without feeling lectured.\n",
    "\n",
    "5. Ensure Entertainment Value:\n",
    "   Maintain a lively, upbeat tone by including:\n",
    "   - Surprising facts or amusing anecdotes\n",
    "   - Playful banter and clever exchanges between hosts\n",
    "   - Dramatic build-ups and enthusiastic descriptions of game-defining moments\n",
    "\n",
    "6. Consider Pacing and Structure:\n",
    "   Structure your script for optimal listener engagement:\n",
    "   - Start immediately with a bold, engaging opening statement\n",
    "   - Alternate smoothly between high-energy recaps and insightful analysis\n",
    "   - Include brief pauses or slower segments to help listeners digest intense sports action\n",
    "   - End energetically, perhaps teasing upcoming sports events or posing a fun challenge to listeners\n",
    "\n",
    "\n",
    "Remember: Always reply in valid JSON format, without code blocks. Begin directly with the JSON output.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create classes to be used for Structured Output against the LLM endpoints\n",
    "\n",
    "Here we use the `pydantic` library to define structured output classes. These classes will help us ensure that the data returned by the AI model is in a consistent format. In this case, we define classes for two different turns with the LLM. The first turn sends raw data about a game, week, season, etc... and the LLM will extract a Topic and Topic Items. The other classes define different length dialogues which are used to generate a \"script\" from an LLM that can then be turned into SSML for TTS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal, List\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "import os\n",
    "\n",
    "\n",
    "class DialogueItem(BaseModel):\n",
    "    \"\"\"A single dialogue item.\"\"\"\n",
    "\n",
    "    speaker: Literal[\"Skeeter\", \"Doug\"]\n",
    "    text: str\n",
    "    sentiment: Literal[\"exciting\", \"serious\", \"empathetic\", \"cheerful\"]\n",
    "\n",
    "class MediumDialogue(BaseModel):\n",
    "    \"\"\"The dialogue between the host and guest.\"\"\"\n",
    "\n",
    "    scratchpad: str\n",
    "    name_of_guest: str\n",
    "    dialogue: List[DialogueItem] = Field(\n",
    "        ..., description=\"A list of dialogue items, typically between 29 to 39 items\"\n",
    "    )\n",
    "\n",
    "class TopicItem(BaseModel):\n",
    "    \"\"\"A single topic item.\"\"\"\n",
    "    time: str = Field(..., description=\"When the topic occurred in the match\")\n",
    "    subject: str = Field(..., description=\"The subject of the topic (examples: 'Injury', 'Play', 'Score', 'Penalty')\")\n",
    "    activity: str = Field(..., description=\"The activity related to the topic\")\n",
    "    description: str = Field(..., description=\"A description of the topic\")\n",
    "class Topics(BaseModel):\n",
    "    \"\"\"A class to represent the topics of a sports podcast episode.\"\"\"\n",
    "    week: str = Field(..., description=\"The date of the topic\")\n",
    "    matchup: str = Field(..., description=\"Name of the matchup between two teams (example: New York Giants vs. Green Bay Packers)\")\n",
    "    topics: List[TopicItem] = Field(\n",
    "        ..., description=\"A list of topic items\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetching raw data\n",
    "\n",
    "This section loads data from the `examples` directory. The initial commit of this notebook is setup to consume a CSV file called `playerstats.csv` but there are commented out examples showing loading of simple .txt files, as well as one showing loading an array of Markdown files and merging them into a single string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "#with open(os.path.join('..', 'examples', \"game-recap.txt\"), \"r\") as f:\n",
    "#    input_text = f.read()\n",
    "content = []\n",
    "with open(os.path.join('..', 'examples', \"playerstats.csv\"), \"r\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    for row in reader:\n",
    "        line = \", \".join(cell.strip() for cell in row if cell.strip())\n",
    "        if line:\n",
    "            content.append(line)\n",
    "input_text = \"\\n\".join(content)\n",
    "\n",
    "# other_updates = [os.path.join('..', 'examples', \"call-center-status1.md\"), os.path.join('..', 'examples', \"call-center-status2.md\"), os.path.join('..', 'examples', \"call-center-status3.md\")]\n",
    "# for update in other_updates:\n",
    "#     with open(update, \"r\") as f:\n",
    "#         input_text += f.read()\n",
    "#print(input_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Summary (Topics Extraction) System Prompt\n",
    "\n",
    "This section defines a system prompt that instructs the AI model to extract topics from the provided data. The topics will be used to guide the conversation in the podcast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's make an initial LLM call to condition the input for the dialogue generation\n",
    "SUMMARY_SYSTEM_PROMPT = \"\"\"\n",
    "You are a world-class sports podcast producer tasked with extracting from the provided input key pieces of data that will be used later to generate a script for a podcast episode. The input may be unstructured or messy, sourced from PDFs or web pages. Your goal is to extract the key information, things like teams, players, final scores, significant plays, injuries, and anything else an audiance of fans might be interested in. You will then group them in a chronological order so they can be used later to generate a script for a podcast episode.\n",
    "\n",
    "\n",
    "# Steps to Follow:\n",
    "1. **Analyze the Input:** \n",
    "    Carefullly examine the text to pull out key information like teams, players, final scores, significant plays, injuries, and anything else fans might be interested in.\n",
    "2. **Group the Information:**\n",
    "    Group the information chronologically by quarter, half, or period.\n",
    "3. **Output the Information:**\n",
    "    Output the information in a JSON format, without any additional text or explanation.\n",
    "\n",
    "Remember: Always reply in valid JSON format, without code blocks. Begin directly with the JSON output.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Topics and Podcast dialogue\n",
    "\n",
    "The section below makes two calls to LLMs. The first call is to extract topics from the raw data. The second call generates a dialogue based on the topics extracted in the first call. The dialogue is structured to include multiple turns, with each turn representing a part of the conversation between the podcast participants.\n",
    "\n",
    "LLM calls are abstracted (implementation can be found in the `utils.py` file). The `call_reasoning_llm` function is used to call an Azure OpenAI Reasioning Model, while the `call_llm` function is used to call a standard Azure OpenAI Model. \n",
    "\n",
    "In the initial commit an experiment was being run to use the `call_reasoning_llm` function to extract topics (given the source data had times and order matters to the dialog), while the `call_llm` function was used to generate the dialogue. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import call_llm, call_reasoning_llm\n",
    "\n",
    "topic_extraction = call_reasoning_llm(SUMMARY_SYSTEM_PROMPT, input_text, Topics)\n",
    "topic_extraction.to_dict()\n",
    "topic_dialog_feeder = topic_extraction.model_dump_json()\n",
    "\n",
    "modified_system_prompt = SYSTEM_PROMPT\n",
    "modified_system_prompt += \"\\n\\nAim for a moderate length, about 3-5 minutes.\"\n",
    "modified_system_prompt += \"\\n\\nOUTPUT LANGUAGE <IMPORTANT>: The the podcast should be English.\"\n",
    "\n",
    "# Call the LLM for the first time\n",
    "first_draft_dialogue = call_llm(modified_system_prompt, topic_dialog_feeder, MediumDialogue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output the first draft dialogue\n",
    "\n",
    "The section outputs the first draft of the dialogue generated by the AI model. This dialogue is structured according to the defined classes and includes multiple turns between the podcast participants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_draft_dialogue.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refine the dialogue\n",
    "\n",
    "This section demonstrates how to refine the dialogue generated by the AI model. It uses the `call_llm` function to make a second call to the AI model, providing it with the initial draft and asking it to improve or refine the conversation. The refined dialogue is then outputted for review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the LLM a second time to improve the dialogue\n",
    "system_prompt_with_dialogue = f\"{modified_system_prompt}\\n\\nHere is the first draft of the dialogue you provided:\\n\\n{first_draft_dialogue.model_dump_json()}.\"\n",
    "final_dialogue = call_llm(system_prompt_with_dialogue, \"Please improve the dialogue. Make it more natural and engaging. Remeber this isn't play-by-play but a recap of a game that has happened.\", MediumDialogue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output the final draft dialogue\n",
    "\n",
    "The section outputs the final draft of the dialogue generated by the AI model. This dialogue is structured according to the defined classes and includes multiple turns between the podcast participants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dialogue.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract the dialogue from the final draft and output it to a JSON file\n",
    "\n",
    "The final two sections of the notebook extract the dialogue from the final draft and output it to a JSON file. This file can be used for further processing, such as converting the dialogue to SSML for text-to-speech (TTS) conversion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "result = json.loads(final_dialogue.choices[0].message.content)\n",
    "result[\"dialogue\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(\"game-recap-script.json\", \"w\") as f:\n",
    "    f.write(json.dumps(result[\"dialogue\"], indent=4, ensure_ascii=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
